

<head>
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
</head>


<div class=WordSection1>

<h2><p >'Reverse Inference' in deep neural&nbsp;networks</p></h2>

<p>Trying to google the term Reverse
Inference usually points you to neuropsychology articles. The articles usually
refer to methods that try to identify one's mental state from the observed
brain activity. The methods mostly involve MRI of human brain that is used for
more or less successful interpretation of patient's ongoing cognitive process</p>

<p><a href="https://www.sciencedirect.com/science/article/pii/S1053811913000141">https://www.sciencedirect.com/science/article/pii/S1053811913000141</a></p>

<p>I have borrowed the fancy term for
much simpler, while similar, problem.</p>

<p>Neuroscientists ask: I know very
little about my patient's brain, but how do I know what he/she feels or sees
when the brain's MRI looks like this?</p>

<p> My simple question is: I'm given a
trained DNN, what the net sees on its input while I get this particular output?
 </p>

<p>There might be more approaches to
such DNN 'reverse engineering'. A very convenient method I used is based on GAN
(Generative Adversarial Network). While GAN's primary purpose is to train
simultaneously both detector and generator, in our case the detector has been
fully trained already and the training set in unknown.</p>

<p>For the following example we train a
CNN on standard MNIST handwritten digits dataset. For an example of regular GAN
on the same dataset, see: <a
href="https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/"
target="_blank">https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/</a></p>

<p>Google colab offers a very convenient environment for our experiment, so the
following code extracts are optimized for it. Let's start with training a CNN
on the MNIST dataset to crate discriminator model:</p>

<p>First, we prepare the environment and the training data:</p>

<p> <img src="image002.jpg"></p>

<p>The model for detector (discriminator) is defined as CNN and trained on the MNIST dataset:</p>

<p><img src="image004.jpg"></p>

<p>Let's check if the trained model
recognizes a custom uploaded image:</p>

<p><img src="image006.jpg"></p>

<p>The result is quite ok, the detected
class actually corresponds with number 6.</p>

<p>Now we have a reasonably trained
model, let's try to build a generator network for creating images.</p>

<p>For this example
the network layout copies the generative part of the above referenced GAN
model.</p>

<p><img src="image008.jpg"></p>
 
<p> now combine the 2 models together</p>

 <p><img src="image009.png"></p>
 <p>and start the training of the
generator model (note the discriminator model is set as not-trainable).</p>

<p>Here we try to get a result for
 class 3 (in MNIST model the character '4')</p>

 <p><img src="image011.jpg"></p>
 
<p>Now we can get a generated - just run inference on the latent space vector with the same
value used for generator model training tr_in = [1,0,0,0,0,...]</p>

 <p> <img src = "image013.jpg"></p>
 <p>The generated image doesn't look
much like handwritten number '4', so let's try how the MNIST trained model
recognizes it.</p>

 <p><img src="image015.jpg"></p>
<p>The detection looks pretty accurate
though the generated result doesn't resemble images of the dataset at all.</p>

<p>Due to random initialization,
repeated training and prediction gives different results, all of them passing
successfully the detection in the discriminator model.</p>

<p><src="image017.jpg"></p>

<p>The result above shows the generator
training with the backpropagation from the existing trained model can easily
create input data fitting the trained detection model, however the images are
not plausible. They generally don't come even close to the training dataset
images. That's why the full GAN concept relies on the training dataset to
differentiate between generated images that fit the discriminator model, but
significantly differ from the expected input.</p>

<p>The technique can be easily misused in adversarial attack
against the model, since the seemingly random noise image would be detected as
specific class with high confidentiality close to 100%.</p>

<p>The full colab
notebook can be downloaded here: <a
href="https://gist.github.com/gogela/974673c9d117962d10fe3a3409099d45"
target="_blank">https://gist.github.com/gogela/974673c9d117962d10fe3a3409099d45</a></p>



</div>

</body>

</html>
