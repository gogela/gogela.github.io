

<head>

</head>


<div class=WordSection1>

<h2><p >'Reverse Inference' in deep neural&nbsp;networks</p></h2>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Trying to google the term Reverse
Inference usually points you to neuropsychology articles. The articles usually
refer to methods that try to identify ones mental state from the observed
brain activity. The methods mostly involve MRI of human brain that is used for
more or less successful interpretation of patients ongoing cognitive process<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>( <a
href="https://www.sciencedirect.com/science/article/pii/S1053811913000141"
target="_blank">https://www.sciencedirect.com/science/article/pii/S1053811913000141</a>)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>I have borrowed the fancy term for
much simpler, while similar, problem.<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Neuroscientists ask: I know very
little about my patients brain, but how do I know what he/she feels or sees
when the brains MRI looks like this?<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><b><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>My simple question is: Im given a
trained DNN, what the net sees on its input while I get this particular output?</span></b><span
style='font-size:12.0pt;font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>There might be more approaches to
such DNN reverse engineering. A very convenient method I used is based on GAN
(Generative Adversarial Network). While GANs primary purpose is to train
simultaneously both detector and generator, in our case the detector has been
fully trained already and the training set in unknown.<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>For the following example we train a
CNN on standard MNIST handwritten digits dataset. For an example of regular GAN
on the same dataset, see: <a
href="https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/"
target="_blank">https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/</a><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Google <span class=SpellE>colab</span>
offers a very convenient environment for our experiment&#8202;&#8202;so the
following code extracts are optimized for it. Lets start with training a CNN
on the MNIST dataset to crate discriminator model:<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span class=GramE><span style='font-size:12.0pt;font-family:
"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'>First</span></span><span
style='font-size:12.0pt;font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'> we prepare the environment and the training data:<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shapetype
 id="_x0000_t75" coordsize="21600,21600" o:spt="75" o:preferrelative="t"
 path="m@4@5l@4@11@9@11@9@5xe" filled="f" stroked="f">
 <v:stroke joinstyle="miter"/>
 <v:formulas>
  <v:f eqn="if lineDrawn pixelLineWidth 0"/>
  <v:f eqn="sum @0 1 0"/>
  <v:f eqn="sum 0 0 @1"/>
  <v:f eqn="prod @2 1 2"/>
  <v:f eqn="prod @3 21600 pixelWidth"/>
  <v:f eqn="prod @3 21600 pixelHeight"/>
  <v:f eqn="sum @0 0 1"/>
  <v:f eqn="prod @6 1 2"/>
  <v:f eqn="prod @7 21600 pixelWidth"/>
  <v:f eqn="sum @8 21600 0"/>
  <v:f eqn="prod @7 21600 pixelHeight"/>
  <v:f eqn="sum @10 21600 0"/>
 </v:formulas>
 <v:path o:extrusionok="f" gradientshapeok="t" o:connecttype="rect"/>
 <o:lock v:ext="edit" aspectratio="t"/>
</v:shapetype><v:shape id="Picture_x0020_9" o:spid="_x0000_i1033" type="#_x0000_t75"
 alt="https://cdn-images-1.medium.com/max/1000/1*Bjvn-xYQHQCycXiFUIxr9g.png"
 style='width:504.6pt;height:287.4pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image001.png" o:title="1*Bjvn-xYQHQCycXiFUIxr9g"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=673 height=383
src="Reverse%20Inference_files/image002.jpg"
alt="https://cdn-images-1.medium.com/max/1000/1*Bjvn-xYQHQCycXiFUIxr9g.png"
v:shapes="Picture_x0020_9"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>The model for detector
(discriminator) is defined as CNN and trained on the MNIST dataset:<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_8" o:spid="_x0000_i1032" type="#_x0000_t75" alt="https://cdn-images-1.medium.com/max/1000/1*6V3eObKJ6iJdDOCJJSen2g.png"
 style='width:511.8pt;height:268.8pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image003.png" o:title="1*6V3eObKJ6iJdDOCJJSen2g"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=682 height=358
src="Reverse%20Inference_files/image004.jpg"
alt="https://cdn-images-1.medium.com/max/1000/1*6V3eObKJ6iJdDOCJJSen2g.png"
v:shapes="Picture_x0020_8"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Lets check if the trained model
recognizes a custom uploaded image:<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_7" o:spid="_x0000_i1031" type="#_x0000_t75" alt="https://cdn-images-1.medium.com/max/1000/1*umgXqwbSroyvRBt1lmAdDA.png"
 style='width:487.2pt;height:396pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image005.png" o:title="1*umgXqwbSroyvRBt1lmAdDA"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=650 height=528
src="Reverse%20Inference_files/image006.jpg"
alt="https://cdn-images-1.medium.com/max/1000/1*umgXqwbSroyvRBt1lmAdDA.png"
v:shapes="Picture_x0020_7"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>The result is quite ok, the detected
class actually corresponds with number 6.<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Now we have a reasonably trained
model&#8202;&#8202;lets try to build a generator network for creating images.<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>For this <span class=GramE>example</span>
the network layout copies the generative part of the above referenced GAN
model.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_6" o:spid="_x0000_i1030" type="#_x0000_t75" alt="https://cdn-images-1.medium.com/max/1000/1*rXesU7khKAm488v4a1-Gvg.png"
 style='width:7in;height:303pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image007.png" o:title="1*rXesU7khKAm488v4a1-Gvg"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=672 height=404
src="Reverse%20Inference_files/image008.jpg"
alt="https://cdn-images-1.medium.com/max/1000/1*rXesU7khKAm488v4a1-Gvg.png"
v:shapes="Picture_x0020_6"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>now combine the 2 models together<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_5" o:spid="_x0000_i1029" type="#_x0000_t75" alt="https://cdn-images-1.medium.com/max/1000/1*9U8FpFtUizFY2WGci6lSgw.png"
 style='width:515.4pt;height:249pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image009.png" o:title="1*9U8FpFtUizFY2WGci6lSgw"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=687 height=332
src="Reverse%20Inference_files/image009.png"
alt="https://cdn-images-1.medium.com/max/1000/1*9U8FpFtUizFY2WGci6lSgw.png"
v:shapes="Picture_x0020_5"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>and start the training of the
generator model (note the discriminator model is set as not-trainable).<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Here we try to get a result for
class 3 (in MNIST model the character 4).<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_4" o:spid="_x0000_i1028" type="#_x0000_t75" alt="https://cdn-images-1.medium.com/max/1000/1*gkuYc78YJmfUN-Mxu1GBRQ.png"
 style='width:493.2pt;height:151.2pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image010.png" o:title="1*gkuYc78YJmfUN-Mxu1GBRQ"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=658 height=202
src="Reverse%20Inference_files/image011.jpg"
alt="https://cdn-images-1.medium.com/max/1000/1*gkuYc78YJmfUN-Mxu1GBRQ.png"
v:shapes="Picture_x0020_4"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Now we can get a generated
image&#8202;&#8202;just run inference on the latent space vector with the same
value used for generator model training <span class=SpellE>tr_in</span> =
[1,0,0,0,0]<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_3" o:spid="_x0000_i1027" type="#_x0000_t75" alt="https://cdn-images-1.medium.com/max/1000/1*4paBmL747Cer3J6EZxqaOg.png"
 style='width:507.6pt;height:207pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image012.png" o:title="1*4paBmL747Cer3J6EZxqaOg"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=677 height=276
src="Reverse%20Inference_files/image013.jpg"
alt="https://cdn-images-1.medium.com/max/1000/1*4paBmL747Cer3J6EZxqaOg.png"
v:shapes="Picture_x0020_3"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>The generated image doesnt look
much like handwritten number 4', so lets try how the MNIST trained model
recognizes it.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_2" o:spid="_x0000_i1026" type="#_x0000_t75" alt="https://cdn-images-1.medium.com/max/1000/1*mWPSOTrPr1unXnQGkMGhUg.png"
 style='width:502.8pt;height:117.6pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image014.png" o:title="1*mWPSOTrPr1unXnQGkMGhUg"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=670 height=157
src="Reverse%20Inference_files/image015.jpg"
alt="https://cdn-images-1.medium.com/max/1000/1*mWPSOTrPr1unXnQGkMGhUg.png"
v:shapes="Picture_x0020_2"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>The detection looks pretty accurate
though the generated result doesnt resemble images of the dataset at all.<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Due to random initialization,
repeated training and prediction gives different results, all of them passing
successfully the detection in the discriminator model.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";mso-no-proof:yes'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_1" o:spid="_x0000_i1025" type="#_x0000_t75" alt="https://cdn-images-1.medium.com/max/1000/1*2iFCkzR2cLcd3IZbK8G18Q.png"
 style='width:517.2pt;height:175.2pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="Reverse%20Inference_files/image016.png" o:title="1*2iFCkzR2cLcd3IZbK8G18Q"/>
</v:shape><![endif]--><![if !vml]><img border=0 width=690 height=234
src="Reverse%20Inference_files/image017.jpg"
alt="https://cdn-images-1.medium.com/max/1000/1*2iFCkzR2cLcd3IZbK8G18Q.png"
v:shapes="Picture_x0020_1"><![endif]></span><span style='font-size:12.0pt;
font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>The result above shows the generator
training with the backpropagation from the existing trained model can easily
create input data fitting the trained detection model, however the images are
not plausible. They generally dont come even close to the training dataset
images. Thats why the full GAN concept relies on the training dataset to
differentiate between generated images that fit the discriminator model, but
significantly differ from the expected input.<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span class=GramE><span style='font-size:12.0pt;font-family:
"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'>However</span></span><span
style='font-size:12.0pt;font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'> the technique can be easily misused in adversarial attack
against the model, since the seemingly random noise image would be detected as
specific class with high confidentiality close to 100%.<o:p></o:p></span></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
line-height:normal'><span style='font-size:12.0pt;font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>The full <span class=SpellE>colab</span>
notebook can be downloaded here: <a
href="https://gist.github.com/gogela/974673c9d117962d10fe3a3409099d45"
target="_blank">https://gist.github.com/gogela/974673c9d117962d10fe3a3409099d45</a><o:p></o:p></span></p>

<p class=MsoNormal><o:p>&nbsp;</o:p></p>

</div>

</body>

</html>
